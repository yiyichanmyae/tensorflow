{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+Tz5WJvyRg6MQ7RPH5IY0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yiyichanmyae/tensorflow/blob/master/2_3_human_vs_horse_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Image Data Generator\n",
        "*   Normalize ( scale )\n",
        "\n"
      ],
      "metadata": {
        "id": "BY_LvmuD5R4u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Gz6VOKTl4tK6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3db7c2fa-547a-4ec1-bef2-efd8127774fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 1027 images belonging to 2 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py:1460: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn(\n",
            "<ipython-input-3-51402f10452b>:81: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(train_XY, epochs = 15, validation_data=validation_XY)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py:1861: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py:1871: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "17/17 [==============================] - 319s 19s/step - loss: 1.8085 - accuracy: 0.6650 - val_loss: 46.9961 - val_accuracy: 0.7907\n",
            "Epoch 2/15\n",
            "17/17 [==============================] - 320s 19s/step - loss: 0.3253 - accuracy: 0.8608 - val_loss: 2.7943 - val_accuracy: 0.9669\n",
            "Epoch 3/15\n",
            "17/17 [==============================] - 292s 17s/step - loss: 0.3010 - accuracy: 0.8598 - val_loss: 21.7611 - val_accuracy: 0.8919\n",
            "Epoch 4/15\n",
            "17/17 [==============================] - 326s 19s/step - loss: 0.3343 - accuracy: 0.8637 - val_loss: 21.6075 - val_accuracy: 0.8900\n",
            "Epoch 5/15\n",
            "17/17 [==============================] - 314s 19s/step - loss: 0.1820 - accuracy: 0.9260 - val_loss: 14.9489 - val_accuracy: 0.9387\n",
            "Epoch 6/15\n",
            "17/17 [==============================] - 326s 19s/step - loss: 0.1893 - accuracy: 0.9299 - val_loss: 16.0269 - val_accuracy: 0.9455\n",
            "Epoch 7/15\n",
            "17/17 [==============================] - 319s 19s/step - loss: 0.1589 - accuracy: 0.9387 - val_loss: 65.8315 - val_accuracy: 0.8345\n",
            "Epoch 8/15\n",
            "17/17 [==============================] - 305s 18s/step - loss: 0.1510 - accuracy: 0.9357 - val_loss: 38.9409 - val_accuracy: 0.8870\n",
            "Epoch 9/15\n",
            "17/17 [==============================] - 315s 19s/step - loss: 0.1044 - accuracy: 0.9620 - val_loss: 10.1953 - val_accuracy: 0.9620\n",
            "Epoch 10/15\n",
            "17/17 [==============================] - 304s 18s/step - loss: 0.2366 - accuracy: 0.9143 - val_loss: 6.7189 - val_accuracy: 0.9367\n",
            "Epoch 11/15\n",
            "17/17 [==============================] - 312s 18s/step - loss: 0.1658 - accuracy: 0.9406 - val_loss: 51.0569 - val_accuracy: 0.8763\n",
            "Epoch 12/15\n",
            "17/17 [==============================] - 322s 19s/step - loss: 0.1386 - accuracy: 0.9474 - val_loss: 9.0827 - val_accuracy: 0.9669\n",
            "Epoch 13/15\n",
            "17/17 [==============================] - 309s 18s/step - loss: 0.0802 - accuracy: 0.9757 - val_loss: 18.2882 - val_accuracy: 0.9484\n",
            "Epoch 14/15\n",
            "17/17 [==============================] - 297s 17s/step - loss: 0.0781 - accuracy: 0.9776 - val_loss: 27.8625 - val_accuracy: 0.9279\n",
            "Epoch 15/15\n",
            "17/17 [==============================] - 323s 19s/step - loss: 0.1264 - accuracy: 0.9533 - val_loss: 33.4473 - val_accuracy: 0.9250\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d04d7e920>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from keras.losses import Loss\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def getDataFromUrl(url_, file_location):\n",
        "  urllib.request.urlretrieve(url_, file_location)\n",
        "\n",
        "def extractZip(zip_, folder_dir):\n",
        "  zip_ref = zipfile.ZipFile(zip_, \"r\")\n",
        "  zip_ref.extractall(folder_dir)\n",
        "  zip_ref.close()\n",
        "\n",
        "# load data\n",
        "training_file_name = \"h-or-h-train.zip\"\n",
        "training_dir = \"h-or-h/training\"\n",
        "validation_file_name = \"h-or-h-validation.zip\"\n",
        "validation_dir = \"h-or-h/vlidation\"\n",
        "\n",
        "training_url = \"https://storage.googleapis.com/learning-datasets/horse-or-human.zip\"\n",
        "getDataFromUrl(training_url, training_file_name)\n",
        "extractZip(training_file_name, training_dir)\n",
        "\n",
        "# urllib.request.urlretrieve(training_url, training_file_name)\n",
        "# zip_ref = zipfile.ZipFile(training_file_name, \"r\")\n",
        "# zip_ref.extractall(training_dir)\n",
        "# zip_ref.close()\n",
        "\n",
        "validation_url = \"https://storage.googleapis.com/learning-datasets/validation-horse-or-human.zip\"\n",
        "getDataFromUrl(validation_url, validation_file_name)\n",
        "extractZip(validation_file_name, validation_dir)\n",
        "\n",
        "# urllib.request.urlretrieve(validation_url, validation_file_name)\n",
        "# zip_ref = zipfile.ZipFile(validation_file_name, \"r\")\n",
        "# zip_ref.extractall(validation_dir)\n",
        "# zip_ref.close()\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# normalize, data augmentation,\n",
        "data_gen_args = dict(rescale = 1./255,\n",
        "                      rotation_range=30,\n",
        "                      width_shift_range=.1,\n",
        "                      height_shift_range=.1,\n",
        "                      shear_range=.1,\n",
        "                      zoom_range=.1,\n",
        "                      horizontal_flip=True,\n",
        "                      featurewise_std_normalization=True\n",
        "                      )\n",
        "\n",
        "data_params = dict(\n",
        "    directory=training_dir,\n",
        "    target_size=(300, 300),\n",
        "    batch_size = 64,\n",
        "    class_mode = 'binary')\n",
        "\n",
        "train_datagen = ImageDataGenerator(**data_gen_args)\n",
        "train_XY = train_datagen.flow_from_directory(**data_params)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(1./255)\n",
        "validation_XY = validation_datagen.flow_from_directory(**data_params)\n",
        "\n",
        "\n",
        "# create model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D( 2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (2,2), activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile( optimizer = \"adam\",\n",
        "              loss= \"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"]\n",
        "              )\n",
        "\n",
        "model.fit_generator(train_XY, epochs = 15, validation_data=validation_XY)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SDObWDk2A8fM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}