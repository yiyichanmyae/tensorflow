{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD6RfaS9H/GRvD3b0O4ADK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yiyichanmyae/tensorflow/blob/master/2_2_fashion_cnn_callbacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DH1VjNTmUEym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2cd3dc7-d18e-486c-e8c3-5b5c39a60d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 25, 25, 64)        1088      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 12, 12, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 10, 10, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                102464    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 141,130\n",
            "Trainable params: 141,130\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 104s 55ms/step - loss: 0.4580 - accuracy: 0.8336\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 96s 51ms/step - loss: 0.3055 - accuracy: 0.8885\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 96s 51ms/step - loss: 0.2609 - accuracy: 0.9032\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 95s 50ms/step - loss: 0.2296 - accuracy: 0.9154\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 100s 53ms/step - loss: 0.2039 - accuracy: 0.9233\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 95s 51ms/step - loss: 0.1867 - accuracy: 0.9299\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 93s 50ms/step - loss: 0.1671 - accuracy: 0.9367\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 95s 50ms/step - loss: 0.1508 - accuracy: 0.9429\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 93s 49ms/step - loss: 0.1386 - accuracy: 0.9473\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 97s 52ms/step - loss: 0.1235 - accuracy: 0.9536\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 93s 49ms/step - loss: 0.1123 - accuracy: 0.9577\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 93s 50ms/step - loss: 0.1021 - accuracy: 0.9604\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.0928 - accuracy: 0.9658\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 94s 50ms/step - loss: 0.0844 - accuracy: 0.9676\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 93s 50ms/step - loss: 0.0776 - accuracy: 0.9705\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 94s 50ms/step - loss: 0.0713 - accuracy: 0.9729\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.0654 - accuracy: 0.9754\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 94s 50ms/step - loss: 0.0631 - accuracy: 0.9760\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 105s 56ms/step - loss: 0.0573 - accuracy: 0.9779\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 91s 48ms/step - loss: 0.0532 - accuracy: 0.9792\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 93s 49ms/step - loss: 0.0512 - accuracy: 0.9807\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 91s 49ms/step - loss: 0.0500 - accuracy: 0.9814\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 94s 50ms/step - loss: 0.0437 - accuracy: 0.9837\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.0445 - accuracy: 0.9835\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 94s 50ms/step - loss: 0.0426 - accuracy: 0.9844\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.0419 - accuracy: 0.9843\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 93s 50ms/step - loss: 0.0386 - accuracy: 0.9855\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.0331 - accuracy: 0.9875\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 93s 50ms/step - loss: 0.0402 - accuracy: 0.9854\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 94s 50ms/step - loss: 0.0327 - accuracy: 0.9884\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.0361 - accuracy: 0.9872\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 94s 50ms/step - loss: 0.0287 - accuracy: 0.9896\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.0325 - accuracy: 0.9884\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 94s 50ms/step - loss: 0.0316 - accuracy: 0.9890\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.0315 - accuracy: 0.9887\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 93s 50ms/step - loss: 0.0285 - accuracy: 0.9894\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 92s 49ms/step - loss: 0.0304 - accuracy: 0.9899\n",
            "Epoch 38/50\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9902\n",
            "Reached 99% accuracy. Cancelling training!\n",
            "1875/1875 [==============================] - 94s 50ms/step - loss: 0.0272 - accuracy: 0.9902\n",
            "313/313 [==============================] - 5s 17ms/step - loss: 0.7066 - accuracy: 0.9090\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7065696716308594, 0.9089999794960022]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# callbacks\n",
        "class myCallbacks(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, eposh, logs={}):\n",
        "    if(logs.get('accuracy')>0.99):\n",
        "      print(\"\\nReached 99% accuracy. Cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallbacks()\n",
        "\n",
        "# data\n",
        "data = tf.keras.datasets.fashion_mnist\n",
        "(train_X, train_Y), (test_X, test_Y) = data.load_data()\n",
        "\n",
        "\n",
        "# normalize\n",
        "train_X = train_X / 255.0\n",
        "test_X = test_X / 255.0\n",
        "\n",
        "# reshape\n",
        "train_X = tf.expand_dims(train_X, axis=3)\n",
        "test_X = tf.expand_dims(test_X, axis=3)\n",
        "\n",
        "# create model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (4, 4), activation=\"relu\", input_shape=train_X.shape[1:]),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\") # multiclass\n",
        "])\n",
        "\n",
        "# compile model\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# train model\n",
        "model.fit(train_X, train_Y, epochs=50, callbacks=[callbacks])\n",
        "\n",
        "# evaluate model\n",
        "model.evaluate(test_X, test_Y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "classification = model.predict(test_X)\n",
        "print(classification[0])\n",
        "print(test_Y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AqYCyCkqPxQ",
        "outputId": "12fb3b4b-f055-4666-b764-c46551dc4c39"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 12ms/step\n",
            "[9.9641122e-19 7.6600458e-23 5.9363609e-13 2.3316739e-18 1.5958890e-28\n",
            " 6.5204352e-14 3.1204918e-19 1.3970516e-07 4.0749010e-14 9.9999982e-01]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BDm6pgqE4f-A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}