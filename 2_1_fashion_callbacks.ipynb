{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwTumxsavhmknKEUokwnne",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yiyichanmyae/tensorflow/blob/master/2_1_fashion_callbacks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4Y-Hv-A7Wblt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57113be7-089e-4b95-ba0d-57f1ecffd7bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4980 - accuracy: 0.8256\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3764 - accuracy: 0.8645\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3364 - accuracy: 0.8770\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3100 - accuracy: 0.8868\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2942 - accuracy: 0.8914\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2796 - accuracy: 0.8968\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2689 - accuracy: 0.8993\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2577 - accuracy: 0.9050\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2484 - accuracy: 0.9072\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2384 - accuracy: 0.9102\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2319 - accuracy: 0.9122\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2229 - accuracy: 0.9165\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2163 - accuracy: 0.9190\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2100 - accuracy: 0.9214\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.2056 - accuracy: 0.9232\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1985 - accuracy: 0.9240\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1933 - accuracy: 0.9271\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1878 - accuracy: 0.9284\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.1823 - accuracy: 0.9318\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1806 - accuracy: 0.9324\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1754 - accuracy: 0.9337\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1705 - accuracy: 0.9355\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1665 - accuracy: 0.9377\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1632 - accuracy: 0.9392\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1601 - accuracy: 0.9398\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1542 - accuracy: 0.9423\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1522 - accuracy: 0.9427\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1485 - accuracy: 0.9444\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1466 - accuracy: 0.9453\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1419 - accuracy: 0.9465\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1398 - accuracy: 0.9460\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1368 - accuracy: 0.9488\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1361 - accuracy: 0.9487\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1327 - accuracy: 0.9497\n",
            "Epoch 35/50\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.1265 - accuracy: 0.9523\n",
            "Reached max accuracy, training will be stoped\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1264 - accuracy: 0.9523\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4807 - accuracy: 0.8797\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[3.3585992e-12 2.4734357e-12 5.7732751e-12 4.7375616e-18 1.2576958e-12\n",
            " 2.0586578e-05 6.3576779e-09 9.2524948e-05 3.1285649e-12 9.9988681e-01]\n",
            "9\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "# callbacks\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get(\"accuracy\")>0.95):\n",
        "      print(\"\\nReached max accuracy, training will be stoped\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "# data\n",
        "(train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data()\n",
        "\n",
        "# normalize data\n",
        "train_X = train_X / 255.0\n",
        "test_X = test_X / 255.0\n",
        "\n",
        "# create the DNN model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "model.fit(train_X, train_Y, epochs=50, callbacks=[callbacks])\n",
        "\n",
        "\n",
        "# evaluate\n",
        "classifications = model.predict(test_X)\n",
        "print(classifications[0])\n",
        "print(test_Y[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "model.evaluate(test_X, test_Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSXjPv_i6s14",
        "outputId": "b0d30039-6e8e-4ca8-a3c8-43aa256a1979"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4807 - accuracy: 0.8797\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4807368516921997, 0.8797000050544739]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}